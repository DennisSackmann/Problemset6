{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "486ef098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import numpy as np  # Import NumPy for numerical operations\n",
    "import pandas as pd  # Import Pandas for data manipulation\n",
    "import tensorflow as tf  # Import TensorFlow for building neural network models\n",
    "import seaborn as sns  # Import Seaborn for statistical plotting\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for creating plots\n",
    "from sklearn.model_selection import train_test_split  # Import train_test_split for splitting datasets\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Import metrics for evaluating models\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor, ElasticNet  # Import linear regression models\n",
    "from sklearn.decomposition import PCA  # Import PCA for dimensionality reduction\n",
    "from sklearn.cross_decomposition import PLSRegression  # Import PLSRegression for partial least squares regression\n",
    "from sklearn.preprocessing import SplineTransformer, StandardScaler  # Import SplineTransformer for spline feature transformation\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor  # Import ensemble regression models\n",
    "from scipy.stats import t # Import t-distribution for statistical tests\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')  # Set the plotting style to Seaborn whitegrid\n",
    "plt.rcParams['figure.figsize'] = (12, 8)  # Set default figure size for plots to 12x8 inches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f41412",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04885242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic variables\n",
    "n_stocks = 10\n",
    "n_months = 24\n",
    "n_characteristics = 5\n",
    "n_macro_factors = 3\n",
    "\n",
    "np.random.seed(42)\n",
    "stock_characteristics = np.random.rand(n_stocks, n_months, n_characteristics)  # Generate random stock characteristic data\n",
    "macro_factors = np.random.rand(n_months, n_macro_factors)  # Generate random macroeconomic factor data\n",
    "\n",
    "zi_t = np.zeros((n_stocks, n_months, n_characteristics * n_macro_factors)) \n",
    "for j in range(n_months):\n",
    "    for i in range(n_stocks):\n",
    "        zi_t[i, j] = np.outer(macro_factors[j],stock_characteristics[i, j]).flatten() \n",
    "\n",
    "# simple linear model for excess return\n",
    "theta = np.random.rand(n_characteristics * n_macro_factors)\n",
    "ri_t_plus_1 = np.zeros((n_stocks, n_months))\n",
    "for j in range(n_months):\n",
    "    for i in range(n_stocks):\n",
    "        ri_t_plus_1[i, j] = zi_t[i, j].dot(theta) + np.random.normal(0, 0.05)\n",
    "\n",
    "# flatten for models\n",
    "zi_t_flattened = zi_t.reshape(n_stocks * n_months, -1)\n",
    "ri_t_flattened = ri_t_plus_1.flatten()\n",
    "\n",
    "# create a dataframe\n",
    "zi_t_df = pd.DataFrame(zi_t_flattened, columns=[f\"z_{k+1}\" for k in range(zi_t_flattened.shape[1])])\n",
    "zi_t_df[\"Stock_ID\"] = np.repeat(range(1, n_stocks + 1), n_months)\n",
    "zi_t_df[\"Month\"] = np.tile(range(1, n_months + 1), n_stocks)\n",
    "\n",
    "\n",
    "ri_t_df = pd.DataFrame({\n",
    "    \"Stock_ID\": np.repeat(range(1, n_stocks + 1), n_months),\n",
    "    \"Month\": np.tile(range(1, n_months + 1), n_stocks),\n",
    "    \"Excess_Return\": ri_t_flattened,\n",
    "    \"Weights\": np.random.rand(n_stocks * n_months)\n",
    "})\n",
    "\n",
    "combined_data = pd.concat([zi_t_df, ri_t_df[[\"Excess_Return\", \"Weights\"]]], axis=1)\n",
    "\n",
    "combined_data.to_csv(\"data/combined_dataframe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14bc81bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z_1</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "      <th>z_8</th>\n",
       "      <th>z_9</th>\n",
       "      <th>z_10</th>\n",
       "      <th>z_11</th>\n",
       "      <th>z_12</th>\n",
       "      <th>z_13</th>\n",
       "      <th>z_14</th>\n",
       "      <th>z_15</th>\n",
       "      <th>Stock_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Excess_Return</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.720892</td>\n",
       "      <td>0.555044</td>\n",
       "      <td>0.453941</td>\n",
       "      <td>0.118303</td>\n",
       "      <td>0.009209</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>0.021033</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630027</td>\n",
       "      <td>0.717598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050481</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.280303</td>\n",
       "      <td>0.194527</td>\n",
       "      <td>0.229140</td>\n",
       "      <td>0.076226</td>\n",
       "      <td>0.028382</td>\n",
       "      <td>0.423251</td>\n",
       "      <td>0.293731</td>\n",
       "      <td>0.345995</td>\n",
       "      <td>0.120179</td>\n",
       "      <td>0.044748</td>\n",
       "      <td>0.667309</td>\n",
       "      <td>0.463103</td>\n",
       "      <td>0.545504</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.552710</td>\n",
       "      <td>0.692436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.662735</td>\n",
       "      <td>0.568804</td>\n",
       "      <td>0.145090</td>\n",
       "      <td>0.124240</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.432485</td>\n",
       "      <td>0.371188</td>\n",
       "      <td>0.094683</td>\n",
       "      <td>0.081076</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.265393</td>\n",
       "      <td>0.227779</td>\n",
       "      <td>0.058102</td>\n",
       "      <td>0.049752</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.831843</td>\n",
       "      <td>0.991256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.182877</td>\n",
       "      <td>0.303367</td>\n",
       "      <td>0.523247</td>\n",
       "      <td>0.430703</td>\n",
       "      <td>0.290392</td>\n",
       "      <td>0.078164</td>\n",
       "      <td>0.129662</td>\n",
       "      <td>0.223641</td>\n",
       "      <td>0.184087</td>\n",
       "      <td>0.124116</td>\n",
       "      <td>0.082786</td>\n",
       "      <td>0.137331</td>\n",
       "      <td>0.236868</td>\n",
       "      <td>0.194974</td>\n",
       "      <td>0.131457</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.315436</td>\n",
       "      <td>0.128394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100114</td>\n",
       "      <td>0.022825</td>\n",
       "      <td>0.047802</td>\n",
       "      <td>0.059946</td>\n",
       "      <td>0.074624</td>\n",
       "      <td>0.486307</td>\n",
       "      <td>0.110871</td>\n",
       "      <td>0.232199</td>\n",
       "      <td>0.291188</td>\n",
       "      <td>0.362489</td>\n",
       "      <td>0.424431</td>\n",
       "      <td>0.096764</td>\n",
       "      <td>0.202656</td>\n",
       "      <td>0.254139</td>\n",
       "      <td>0.316368</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.683045</td>\n",
       "      <td>0.104110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        z_1       z_2       z_3       z_4       z_5       z_6       z_7  \\\n",
       "0  0.284000  0.720892  0.555044  0.453941  0.118303  0.009209  0.023375   \n",
       "1  0.050481  0.018796  0.280303  0.194527  0.229140  0.076226  0.028382   \n",
       "2  0.014065  0.662735  0.568804  0.145090  0.124240  0.009179  0.432485   \n",
       "3  0.182877  0.303367  0.523247  0.430703  0.290392  0.078164  0.129662   \n",
       "4  0.100114  0.022825  0.047802  0.059946  0.074624  0.486307  0.110871   \n",
       "\n",
       "        z_8       z_9      z_10      z_11      z_12      z_13      z_14  \\\n",
       "0  0.017997  0.014719  0.003836  0.008286  0.021033  0.016194  0.013244   \n",
       "1  0.423251  0.293731  0.345995  0.120179  0.044748  0.667309  0.463103   \n",
       "2  0.371188  0.094683  0.081076  0.005632  0.265393  0.227779  0.058102   \n",
       "3  0.223641  0.184087  0.124116  0.082786  0.137331  0.236868  0.194974   \n",
       "4  0.232199  0.291188  0.362489  0.424431  0.096764  0.202656  0.254139   \n",
       "\n",
       "       z_15  Stock_ID  Month  Excess_Return   Weights  \n",
       "0  0.003452         1      1       0.630027  0.717598  \n",
       "1  0.545504         1      2       1.552710  0.692436  \n",
       "2  0.049752         1      3       0.831843  0.991256  \n",
       "3  0.131457         1      4       1.315436  0.128394  \n",
       "4  0.316368         1      5       1.683045  0.104110  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/combined_dataframe.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364fd6a5",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "765d408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build training, validation and testing sets\n",
    "X_full = data[[col for col in data.columns if col.startswith(\"z_\")]]\n",
    "Y_full = data[\"Excess_Return\"]\n",
    "\n",
    "X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n",
    "    X_full, Y_full, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_trainval, Y_trainval, test_size=0.2857, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb23a16",
   "metadata": {},
   "source": [
    "# Model Training Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d33a25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# OLS Regression\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train, Y_train)\n",
    "\n",
    "# Weighted Linear Regression\n",
    "weighted_ols_model = LinearRegression()\n",
    "weighted_ols_model.fit(X_train, Y_train, sample_weight=np.random.rand(len(Y_train)))    \n",
    "\n",
    "# HUber Regression\n",
    "huber_model = HuberRegressor()\n",
    "huber_model.fit(X_train, Y_train)\n",
    "\n",
    "# Elastic Net Regression\n",
    "best_mse = float('inf')\n",
    "best_alpha = None\n",
    "best_l1_ratio = None\n",
    "\n",
    "for alpha in [0.01, 0.1, 1.0, 10.0]:\n",
    "    for l1_ratio in [0.1, 0.5, 0.9]:\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=True, max_iter=1000, random_state=42)\n",
    "        model.fit(X_train, Y_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_mse = mean_squared_error(Y_val, y_val_pred)\n",
    "\n",
    "        if val_mse < best_mse:\n",
    "            best_mse = val_mse\n",
    "            best_alpha = alpha\n",
    "            best_l1_ratio = l1_ratio\n",
    "\n",
    "elastic_net_model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, fit_intercept=True, max_iter=1000, random_state=42)\n",
    "elastic_net_model.fit(X_train, Y_train)\n",
    "\n",
    "# PCR Regression\n",
    "best_pcr_mse = float('inf')\n",
    "best_n_components = None\n",
    "for n_components in range(1, min(X_train.shape[1], 20) + 1):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "\n",
    "    lr_pcr = LinearRegression()\n",
    "    lr_pcr.fit(X_train_pca, Y_train)\n",
    "    \n",
    "    y_val_pred = lr_pcr.predict(X_val_pca)\n",
    "    mse = mean_squared_error(Y_val, y_val_pred)\n",
    "\n",
    "    if mse < best_pcr_mse:\n",
    "        best_pcr_mse = val_mse\n",
    "        best_n_components = n_components\n",
    "\n",
    "pca_model = PCA(n_components=best_n_components)\n",
    "X_train_pca = pca_model.fit_transform(X_train)\n",
    "lr_pcr_model = LinearRegression()\n",
    "lr_pcr_model.fit(X_train_pca, Y_train)\n",
    "\n",
    "# PLS Regression\n",
    "best_pls_mse = float('inf')\n",
    "best_n_components_pls = None\n",
    "for n_components in range(1, min(X_train.shape[1], 20) + 1):\n",
    "    pls = PLSRegression(n_components=n_components)\n",
    "    pls.fit(X_train, Y_train)\n",
    "    \n",
    "    y_val_pred = pls.predict(X_val)\n",
    "    mse = mean_squared_error(Y_val, y_val_pred)\n",
    "\n",
    "    if mse < best_pls_mse:\n",
    "        best_pls_mse = mse\n",
    "        best_n_components_pls = n_components\n",
    "\n",
    "pls_model = PLSRegression(n_components=best_n_components_pls)\n",
    "pls_model.fit(X_train, Y_train)\n",
    "\n",
    "# Generalized Linear Model\n",
    "spline_transformer = SplineTransformer(n_knots=5, degree=2, include_bias=False, knots=\"uniform\")\n",
    "X_train_spline = spline_transformer.fit_transform(X_train)\n",
    "X_val_spline = spline_transformer.transform(X_val)\n",
    "\n",
    "l1_ratios = [0.1, 0.5, 0.9]\n",
    "alphas = np.logspace(-3, 1, 10)\n",
    "best_model = None\n",
    "best_val_mse = float('inf')\n",
    "for l1_ratio in l1_ratios:\n",
    "    for alpha in alphas:\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=True, max_iter=1000, random_state=42)\n",
    "        model.fit(X_train_spline, Y_train)\n",
    "        \n",
    "        y_val_pred = model.predict(X_val_spline)\n",
    "        val_mse = mean_squared_error(Y_val, y_val_pred)\n",
    "\n",
    "        if val_mse < best_val_mse:\n",
    "            best_val_mse = val_mse\n",
    "            best_model = model\n",
    "\n",
    "glm_model = best_model\n",
    "\n",
    "# Neural Network Model\n",
    "\n",
    "def create_model(learning_rate=0.01, neurons_layer1=32, neurons_layer2=16, neurons_layer3=8):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(zi_t_flattened.shape[1],)),\n",
    "        tf.keras.layers.Dense(neurons_layer1, activation='relu'),\n",
    "        tf.keras.layers.Dense(neurons_layer2, activation='relu'),\n",
    "        tf.keras.layers.Dense(neurons_layer3, activation='relu'),\n",
    "        tf.keras.layers.Dense(1) \n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "neurons_layer1_options = [32, 64]\n",
    "neurons_layer2_options = [16, 32]\n",
    "neurons_layer3_options = [8, 16]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for n1 in neurons_layer1_options:\n",
    "        for n2 in neurons_layer2_options:\n",
    "            for n3 in neurons_layer3_options:\n",
    "                model = create_model(learning_rate=lr, \n",
    "                                     neurons_layer1=n1, \n",
    "                                     neurons_layer2=n2, \n",
    "                                     neurons_layer3=n3)\n",
    "                \n",
    "                history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=50, batch_size=32, verbose=0, callbacks=[\n",
    "                    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "                ])\n",
    "                \n",
    "                val_loss = min(history.history['val_loss'])\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model = model\n",
    "\n",
    "nn_model = best_model\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "brt_best_params = None\n",
    "brt_best_model = None\n",
    "brt_best_rmse = float('inf')\n",
    "\n",
    "for n_estimators in [50, 100, 200]:\n",
    "    for learning_rate in [0.01, 0.1, 0.2]:\n",
    "        for max_depth in [3, 5, 7]:\n",
    "            model = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
    "            model.fit(X_train, Y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_rmse = np.sqrt(mean_squared_error(Y_val, val_pred))\n",
    "\n",
    "            if val_rmse < brt_best_rmse:\n",
    "                brt_best_rmse = val_rmse\n",
    "                brt_best_params = {\"n_estimators\":n_estimators, \"learning_rate\": learning_rate, \"max_depth\": max_depth}\n",
    "                brt_best_model = model\n",
    "\n",
    "brt_model = brt_best_model\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_best_params = None\n",
    "rf_best_model = None\n",
    "rf_best_rmse = float('inf')\n",
    "\n",
    "for n_estimators in [50, 100, 200]:\n",
    "    for max_depth in [3, 5, 7]:\n",
    "        for min_samples_split in [2, 5, 10]:\n",
    "            model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "            model.fit(X_train, Y_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_rmse = np.sqrt(mean_squared_error(Y_val, val_pred))\n",
    "\n",
    "            if val_rmse < rf_best_rmse:\n",
    "                rf_best_rmse = val_rmse\n",
    "                rf_best_params = {\"n_estimators\": n_estimators, \"max_depth\": max_depth, \"min_samples_split\": min_samples_split}\n",
    "                rf_best_model = model\n",
    "\n",
    "rf_model = rf_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eefa27",
   "metadata": {},
   "source": [
    "# Prediction Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3db2f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "def predict_all_models(X):\n",
    "    \n",
    "    return {\n",
    "        \"OLS\": ols_model.predict(X),\n",
    "        \"Weighted OLS\": weighted_ols_model.predict(X),\n",
    "        \"Huber\": huber_model.predict(X),\n",
    "        \"Elastic Net\": elastic_net_model.predict(X),\n",
    "        \"PCR\": lr_pcr_model.predict(pca_model.transform(X)),\n",
    "        \"PLS\": pls_model.predict(X).flatten(),\n",
    "        \"Generalized_Linear_Model\": glm_model.predict(spline_transformer.transform(X)),\n",
    "        \"Neural_Network\": nn_model.predict(X).flatten(),\n",
    "        \"Boosted_Regression_Trees\": brt_model.predict(X),\n",
    "        \"Random_Forest\": rf_model.predict(X)\n",
    "    }\n",
    "\n",
    "prediction = predict_all_models(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c4c59c",
   "metadata": {},
   "source": [
    "# Out-of-Sample R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08984834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_r2(Y_true, Y_pred):\n",
    "     ss_res = np.sum((Y_true - Y_pred) ** 2)\n",
    "     ss_tot = np.sum((Y_true - np.mean(Y_true)) ** 2)\n",
    "     return 1 - (ss_res / ss_tot)\n",
    "\n",
    "r2_results = {name: calc_r2(Y_test, pred) for name, pred in prediction.items()}\n",
    "df_r2 = pd.DataFrame.from_dict(r2_results, orient='index', columns=['R²']).to_csv(\"/Users/dennis/Documents/Uni/FDS/PS6/data/r2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b827120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.996831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighted OLS</td>\n",
       "      <td>0.996354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huber</td>\n",
       "      <td>0.996605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.990315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCR</td>\n",
       "      <td>0.996831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLS</td>\n",
       "      <td>0.996876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Generalized_Linear_Model</td>\n",
       "      <td>0.990550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural_Network</td>\n",
       "      <td>0.990685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Boosted_Regression_Trees</td>\n",
       "      <td>0.929344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.889388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Unnamed: 0        R²\n",
       "0                       OLS  0.996831\n",
       "1              Weighted OLS  0.996354\n",
       "2                     Huber  0.996605\n",
       "3               Elastic Net  0.990315\n",
       "4                       PCR  0.996831\n",
       "5                       PLS  0.996876\n",
       "6  Generalized_Linear_Model  0.990550\n",
       "7            Neural_Network  0.990685\n",
       "8  Boosted_Regression_Trees  0.929344\n",
       "9             Random_Forest  0.889388"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_data = pd.read_csv(\"/Users/dennis/Documents/Uni/FDS/PS6/data/r2_results.csv\")\n",
    "\n",
    "r2_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff432861",
   "metadata": {},
   "source": [
    "# Diebold-Mariano Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2267dcbe",
   "metadata": {},
   "source": [
    "# Variable Importance Calculations & Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e491dd",
   "metadata": {},
   "source": [
    "# Auxiliary Functions and Decile Portfolio Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
